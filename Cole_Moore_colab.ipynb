{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+uqgTp+IfPeccZDfJkY4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PintoBI/Cole-Moore/blob/main/Cole_Moore_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pintobi/Cole-Moore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yu2EqKKsU5",
        "outputId": "f92c3f43-f2d7-4f77-94f1-bae8e0f92f27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cole-Moore'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 25 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 1.27 MiB | 8.13 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "5Lj_8vgi4PeO",
        "outputId": "daab4b47-8200-4708-fa63-883045ac331f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your electrophysiology data file (e.g., .csv, .txt, .asc). If not file is ulpoaded example simulated data will be used\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b88972ee-6976-48d1-ad33-6c3ab05d264d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b88972ee-6976-48d1-ad33-6c3ab05d264d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import the module\n",
        "import sys\n",
        "sys.path.append('/content/Cole-Moore')\n",
        "from data_loader import load_data\n",
        "\n",
        "# Import other necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload a data file\n",
        "print(\"Please upload your electrophysiology data file (e.g., .csv, .txt, .asc). If not file is ulpoaded example simulated data will be used\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process the uploaded file\n",
        "if uploaded:\n",
        "    file_name = next(iter(uploaded))\n",
        "    file_content = uploaded[file_name]\n",
        "    print(f\"\\nUploaded file: {file_name}\")\n",
        "elif os.path.exists('/content/Cole-Moore/Example/simulation.txt'):\n",
        "    file_name = '/content/Cole-Moore/Example/simulation.txt'\n",
        "    with open(file_name, 'rb') as f:\n",
        "        file_content = f.read()\n",
        "    print(f\"\\nNo file uploaded. Using sample file: {file_name}\")\n",
        "else:\n",
        "    print(\"No file uploaded and sample file not found. Please upload a file manually.\")\n",
        "    file_name = None\n",
        "    file_content = None\n",
        "\n",
        "if file_name and file_content:\n",
        "    # Use your load_data function\n",
        "    data = load_data(\n",
        "        filename=file_name,\n",
        "        file_content=file_content,\n",
        "        header_lines=1,\n",
        "        time_col_hint='Time',\n",
        "        delimiter=None\n",
        "    )\n",
        "\n",
        "    if data is not None:\n",
        "        print(\"\\n--- Data Preview ---\")\n",
        "        display(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Example script for using the voltage_converter module\n",
        "\n",
        "This script assumes that 'data' has already been loaded and is available in the environment.\n",
        "It converts sweep column headers to voltage values using the voltage_converter module.\n",
        "\"\"\"\n",
        "\n",
        "# Import the voltage_converter module\n",
        "from voltage_converter import rename_sweep_columns_to_voltage\n",
        "\n",
        "# Check if data is available\n",
        "if 'data' in locals() and data is not None:\n",
        "    print(\"\\n--- Renaming Sweep Columns to Voltage Values ---\")\n",
        "\n",
        "    # User-specified voltage parameters\n",
        "    initial_voltage = -60   # mV, voltage of the first sweep\n",
        "    voltage_step = -5     # mV, voltage difference between consecutive sweeps\n",
        "\n",
        "    print(f\"Initial voltage: {initial_voltage} mV\")\n",
        "    print(f\"Voltage step: {voltage_step} mV\")\n",
        "\n",
        "    # Rename the columns\n",
        "    voltage_data = rename_sweep_columns_to_voltage(\n",
        "        data,\n",
        "        time_col='Time (ms)',\n",
        "        initial_voltage=initial_voltage,\n",
        "        voltage_step=voltage_step\n",
        "    )\n",
        "\n",
        "    # Replace data with the renamed version for subsequent processing\n",
        "    data = voltage_data\n",
        "\n",
        "    # Display the first few rows to verify\n",
        "    print(\"\\n--- Data with Voltage Headers (first 5 rows) ---\")\n",
        "    from IPython.display import display\n",
        "    display(data.head())\n",
        "\n",
        "    print(\"\\n--- Column Renaming Complete ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Skipping Sweep to Voltage Renaming ---\")\n",
        "    print(\"Variable 'data' not found. Please run the data import cell first.\")"
      ],
      "metadata": {
        "id": "9zucQFX64fRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Example script for using the normalizer module\n",
        "\n",
        "This script assumes that 'data' has already been loaded and is available in the environment.\n",
        "It normalizes the data using the specified method and time window.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Import the normalizer module\n",
        "from normalize import normalize_data_window\n",
        "\n",
        "# --- Configure and Apply Normalization ---\n",
        "# Check if data exists\n",
        "if 'data' in locals() and data is not None:\n",
        "    print(\"\\n--- Configuring Normalization ---\")\n",
        "\n",
        "    # --- Select Normalization Parameters ---\n",
        "    # Options: 'subtract', 'divide', 'normalize', 'none'\n",
        "    normalization_method = 'divide'\n",
        "\n",
        "    # Time window (in ms) for calculating baseline or min/max\n",
        "    # Set to None to use the start/end of the data trace\n",
        "    norm_start_time_ms = 1     # ms, Start time for normalization window\n",
        "    norm_end_time_ms = 100      # ms, End time for normalization window\n",
        "\n",
        "    print(f\"Selected Method: {normalization_method}\")\n",
        "    print(f\"Calculation Window: [{norm_start_time_ms}, {norm_end_time_ms}] ms\")\n",
        "\n",
        "    # Apply normalization\n",
        "    normalized_data = normalize_data_window(\n",
        "        data,\n",
        "        time_col='Time (ms)',  # Should be standard name from load_data\n",
        "        method=normalization_method,\n",
        "        start_time_ms=norm_start_time_ms,\n",
        "        end_time_ms=norm_end_time_ms\n",
        "    )\n",
        "\n",
        "    if normalized_data is not None:\n",
        "        print(\"\\n--- Normalized Data (first 5 rows) ---\")\n",
        "        display(normalized_data.head())\n",
        "\n",
        "        # Optional: Basic plot to compare raw vs normalized for the first sweep\n",
        "        first_sweep = normalized_data.columns[4]  # Get name of first sweep column\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(data['Time (ms)'], data[first_sweep], label=f'{first_sweep} (Raw)', alpha=0.7)\n",
        "        plt.plot(normalized_data['Time (ms)'], normalized_data[first_sweep], label=f'{first_sweep} (Normalized)', alpha=0.7)\n",
        "        plt.title(f'Raw vs Normalized Data ({normalization_method}) - {first_sweep}')\n",
        "        plt.xlabel('Time (ms)')\n",
        "        plt.ylabel('Current')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.6)\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"\\n--- Normalization Failed ---\")\n",
        "        # You might want to assign data to normalized_data here if you want subsequent cells to run\n",
        "        # normalized_data = data.copy()\n",
        "        # print(\"Using raw data for subsequent steps as normalization failed.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Skipping Normalization ---\")\n",
        "    print(\"Variable 'data' not found. Please run the data import cell first.\")\n",
        "    normalized_data = None  # Ensure variable exists but is None\n"
      ],
      "metadata": {
        "id": "Yd_7uG5h645y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "\n",
        "from exponential_fit import analyze_with_exponential_fit, visualize_exponential_fits\n",
        "# (Optionally available too: analyze_single, analyze_double, analyze_triple)\n",
        "\n",
        "# --- Run Exponential Fit Analysis ---\n",
        "if 'normalized_data' in locals() and normalized_data is not None:\n",
        "    print(\"\\n--- Configuring Exponential Fit Analysis ---\")\n",
        "\n",
        "    # --- Set Analysis Parameters ---\n",
        "    exp_type = 'single'        # 'single' | 'double' | 'triple'\n",
        "    # n_exp = 3                 # (optional override) 1, 2, or 3 â€” uncomment to force it\n",
        "\n",
        "    start_time = 0.6          # ms\n",
        "    end_time = 100              # ms\n",
        "    baseline_percent = 30      # %\n",
        "    max_percent = 99           # %\n",
        "    display_max_time = 10      # ms\n",
        "\n",
        "    print(f\"Selected Exponential Type: {exp_type}\")\n",
        "    print(f\"Fitting Window: [{start_time}, {end_time if end_time is not None else 'end'}] ms\")\n",
        "    print(f\"Fitting Range: {baseline_percent}% to {max_percent}% of amplitude\")\n",
        "    print(f\"Display Range: 0 to {display_max_time} ms\")\n",
        "\n",
        "    # Run the analysis\n",
        "    exp_fit_results = analyze_with_exponential_fit(\n",
        "        normalized_data,\n",
        "        time_col='Time (ms)',\n",
        "        start_time=start_time,\n",
        "        end_time=end_time,\n",
        "        baseline_percent=baseline_percent,\n",
        "        max_percent=max_percent,\n",
        "        exp_type=exp_type,   # keep this...\n",
        "        # n_exp=n_exp,       # ...or pass this to override exp_type\n",
        "    )\n",
        "\n",
        "    # Visualize (NOTE: no exp_type parameter here)\n",
        "    if exp_fit_results:\n",
        "        results_df = visualize_exponential_fits(\n",
        "            normalized_data,\n",
        "            exp_fit_results,\n",
        "            time_col='Time (ms)',\n",
        "            x_min=0,\n",
        "            x_max=display_max_time,\n",
        "            max_sweeps=6\n",
        "        )\n",
        "\n",
        "        # Save & download\n",
        "        if results_df is not None:\n",
        "            results_filename = f\"cole_moore_exp_fit_results_{exp_type}.csv\"\n",
        "            results_df.to_csv(results_filename, index=False)\n",
        "            print(f\"Results saved to {results_filename}\")\n",
        "            #files.download(results_filename)\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Skipping Exponential Fit Analysis ---\")\n",
        "    print(\"Variable 'normalized_data' not found. Please run the data normalization cell first.\")\n"
      ],
      "metadata": {
        "id": "ulXZKS5B855i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script for using the trace_aligner module for Cole-Moore analysis\n",
        "\n",
        "This script aligns traces by their rising phase (activation kinetics) and visualizes\n",
        "the results. It handles both positive and negative currents automatically.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "\n",
        "# Import the trace_aligner module\n",
        "from trace_aligner import align_traces, visualize_aligned_traces, plot_cole_moore_shifts\n",
        "\n",
        "# --- Run Trace Alignment Analysis ---\n",
        "if 'normalized_data' in locals() and normalized_data is not None:\n",
        "    print(\"\\n--- Configuring Trace Alignment Analysis ---\")\n",
        "\n",
        "    # --- Set Analysis Parameters ---\n",
        "    rising_phase_only = True       # Focus only on rising phase (activation) for alignment\n",
        "    alignment_method = 'single_threshold'  # 'single_threshold', 'multi_threshold', or 'curve_fit'\n",
        "    alignment_threshold = 0.5      # For single threshold method - percent of amplitude (0.0-1.0)\n",
        "    threshold_points = 1           # For multi-threshold method - number of points to use\n",
        "    exclude_outliers = False        # Exclude outliers from alignment\n",
        "    reference_sweep = '-60 mV'     # None for automatic selection based on typical kinetics\n",
        "    start_time = 0.1               # ms, Start time for analysis (None for all data)\n",
        "    max_shift = 50.0               # ms, Maximum allowable shift\n",
        "    display_x_max = 15             # ms, Maximum time to display on x-axis\n",
        "    auto_detect_polarity = True    # Automatically detect negative currents\n",
        "    num_sweeps = 6\n",
        "\n",
        "    print(f\"Alignment Method: {alignment_method}\")\n",
        "    if alignment_method == 'single_threshold':\n",
        "        print(f\"Alignment Threshold: {alignment_threshold*100}% of peak\")\n",
        "    elif alignment_method == 'multi_threshold':\n",
        "        print(f\"Using {threshold_points} threshold points for robust alignment\")\n",
        "\n",
        "    print(f\"Reference Sweep: {'Auto-select' if reference_sweep is None else reference_sweep}\")\n",
        "    print(f\"Analysis Start Time: {start_time if start_time is not None else 'Beginning of trace'} ms\")\n",
        "    print(f\"Exclude Outliers: {'Yes' if exclude_outliers else 'No'}\")\n",
        "    print(f\"Rising Phase Only: {'Yes' if rising_phase_only else 'No'}\")\n",
        "    print(f\"Auto-Detect Polarity: {'Yes' if auto_detect_polarity else 'No'}\")\n",
        "\n",
        "        # Run the alignment\n",
        "    shift_results = align_traces(\n",
        "        normalized_data,\n",
        "        time_col='Time (ms)',\n",
        "        reference_sweep=reference_sweep,\n",
        "        start_time=start_time,\n",
        "        rising_phase_only=rising_phase_only,\n",
        "        alignment_threshold=alignment_threshold,\n",
        "        alignment_method=alignment_method,\n",
        "        threshold_points=threshold_points,\n",
        "        exclude_outliers=exclude_outliers,\n",
        "        max_shift=max_shift,\n",
        "        auto_detect_polarity=auto_detect_polarity\n",
        "\n",
        "    )\n",
        "\n",
        "    # Visualize the results\n",
        "    if shift_results:\n",
        "        results_df = visualize_aligned_traces(\n",
        "            normalized_data,\n",
        "            shift_results,\n",
        "            time_col='Time (ms)',\n",
        "            max_sweeps=num_sweeps ,  # Maximum number of sweeps to show\n",
        "            x_min=0,\n",
        "            x_max=display_x_max,\n",
        "            highlight_rising_phase=False,\n",
        "            auto_detect_polarity=auto_detect_polarity\n",
        "        )\n",
        "\n",
        "        # Create a separate plot of Cole-Moore shift vs. voltage\n",
        "        plot_cole_moore_shifts(results_df)\n",
        "\n",
        "        # Save results to CSV\n",
        "        if results_df is not None:\n",
        "            results_filename = \"cole_moore_shift_results.csv\"\n",
        "            results_df.to_csv(results_filename, index=False)\n",
        "            print(f\"Results saved to {results_filename}\")\n",
        "\n",
        "            # Download file in Colab (uncomment to enable)\n",
        "            # files.download(results_filename)\n",
        "    else:\n",
        "        print(\"No valid alignment results to visualize.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Skipping Trace Alignment Analysis ---\")\n",
        "    print(\"Variable 'normalized_data' not found. Please run the data normalization cell first.\")"
      ],
      "metadata": {
        "id": "JpTqVAmD_BEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script for using the derivative_analysis module for Cole-Moore analysis\n",
        "\n",
        "This script assumes that 'raw_data' has already been loaded and is available\n",
        "in the environment. It performs derivative peak analysis and visualizes the results.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "\n",
        "# Import the derivative_analyzer module\n",
        "from derivative_analysis import analyze_derivative_peaks, visualize_derivative_peaks\n",
        "\n",
        "# --- Run Derivative Peak Analysis ---\n",
        "if 'data' in locals() and data is not None:\n",
        "    print(\"\\n--- Configuring Derivative Peak Analysis ---\")\n",
        "\n",
        "    # --- Set Analysis Parameters ---\n",
        "    start_time = 0.1         # ms, Start time for analysis (None to use all data)\n",
        "    window_length = 11       # Window length for smoothing (must be odd)\n",
        "    polyorder = 3           # Polynomial order for Savitzky-Golay filter\n",
        "    min_peak_height = None     # Minimum height for peak detection (None for auto)\n",
        "    peak_prominence = 1e-7   # Minimum prominence for peak detection\n",
        "    num_sweeps = 6             # Num of sweeps to plot\n",
        "\n",
        "    # Display parameters\n",
        "    x_min = 0                  # ms, Minimum time for x-axis in plots\n",
        "    x_max = 10                 # ms, Maximum time for x-axis in plots\n",
        "    y_min_deriv = -2          # Minimum value for y-axis in derivative plot (None for auto)\n",
        "    y_max_deriv =20 # Maximum value for y-axis in derivative plot (None for auto)\n",
        "\n",
        "    print(f\"Analysis Start Time: {start_time} ms\")\n",
        "    print(f\"Smoothing Window: {window_length} points\")\n",
        "    print(f\"Polynomial Order: {polyorder}\")\n",
        "    print(f\"Plot Range X: {x_min} to {x_max} ms\")\n",
        "    print(f\"Plot Range Y for derivative: {y_min_deriv} to {y_max_deriv} (auto if None)\")\n",
        "\n",
        "    # Run the analysis on data\n",
        "    print(\"\\nAnalyzing data with derivative peak method...\")\n",
        "    derivative_results = analyze_derivative_peaks(\n",
        "        data,\n",
        "        time_col='Time (ms)',\n",
        "        start_time=start_time,\n",
        "        window_length=window_length,\n",
        "        polyorder=polyorder,\n",
        "        min_peak_height=min_peak_height,\n",
        "        peak_prominence=peak_prominence,\n",
        "        early_activation_bias= False\n",
        "    )\n",
        "\n",
        "    # Visualize the results\n",
        "    if derivative_results:\n",
        "        results_df = visualize_derivative_peaks(\n",
        "            data,\n",
        "            derivative_results,\n",
        "            time_col='Time (ms)',\n",
        "            window_length=window_length,\n",
        "            polyorder=polyorder,\n",
        "            start_time=start_time,\n",
        "            x_min=x_min,\n",
        "            x_max=x_max,\n",
        "            max_sweeps=num_sweeps,\n",
        "            y_min_deriv=y_min_deriv,\n",
        "            y_max_deriv=y_max_deriv\n",
        "        )\n",
        "\n",
        "        # Save results to CSV\n",
        "        if results_df is not None:\n",
        "            results_filename = \"cole_moore_derivative_peak_results.csv\"\n",
        "            results_df.to_csv(results_filename, index=False)\n",
        "            print(f\"Results saved to {results_filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Skipping Derivative Peak Analysis ---\")\n",
        "    print(\"Variable 'data' not found. Please run the data import cell first.\")"
      ],
      "metadata": {
        "id": "QxC4g8tLApAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script for using the cole_moore_comparator module\n",
        "\n",
        "This script assumes that the analysis result CSV files exist in the current directory.\n",
        "It compares the Cole-Moore shift results from different analysis methods.\n",
        "\"\"\"\n",
        "\n",
        "# Import the cole_moore_comparator module\n",
        "from compare_methods import compare_cole_moore_methods\n",
        "\n",
        "# --- Run Cole-Moore Methods Comparison ---\n",
        "print(\"\\n--- Comparing Cole-Moore Analysis Methods ---\")\n",
        "\n",
        "# Specify paths to the CSV files from each method\n",
        "exp_file = \"cole_moore_exp_fit_results_single.csv\"\n",
        "shift_file = \"cole_moore_shift_results.csv\"\n",
        "derivative_file = \"cole_moore_derivative_peak_results.csv\"\n",
        "\n",
        "# Check for existing files\n",
        "import os\n",
        "all_files_exist = True\n",
        "\n",
        "for file_path, method_name in [\n",
        "    (exp_file, \"Exponential Fit\"),\n",
        "    (shift_file, \"Trace Alignment\"),\n",
        "    (derivative_file, \"Derivative Peak\")\n",
        "]:\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Warning: {file_path} not found. {method_name} results will not be included.\")\n",
        "        all_files_exist = False\n",
        "\n",
        "if all_files_exist:\n",
        "    print(\"All result files found. Proceeding with comparison.\")\n",
        "else:\n",
        "    print(\"Note: Missing files will be skipped in the comparison.\")\n",
        "\n",
        "# Run comparison\n",
        "compare_cole_moore_methods(\n",
        "    exp_csv=exp_file,\n",
        "    shift_csv=shift_file,\n",
        "    derivative_csv=derivative_file,\n",
        "    invert_shifts=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- Comparison Complete ---\")\n"
      ],
      "metadata": {
        "id": "gaUWMB4UDne1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cole_moore_correlation import correlate_cole_moore\n",
        "\n",
        "correlate_cole_moore(\n",
        "    exp_csv=\"cole_moore_exp_fit_results_single.csv\",\n",
        "    shift_csv=\"cole_moore_shift_results.csv\",\n",
        "    derivative_csv=\"cole_moore_derivative_peak_results.csv\",\n",
        "    invert_shifts=True\n",
        ")"
      ],
      "metadata": {
        "id": "E58KI4qejkc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cole_moore_baseline_correlation import correlate_cole_moore_baselined\n",
        "\n",
        "# Usage example for Google Colab:\n",
        "print(\"Cole-Moore Methods Correlation Analysis with Baselined Data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Specify your CSV file paths here\n",
        "exp_file = \"cole_moore_exp_fit_results_single.csv\"\n",
        "shift_file = \"cole_moore_shift_results.csv\"\n",
        "derivative_file = \"cole_moore_derivative_peak_results.csv\"\n",
        "\n",
        "# Run the correlation analysis with baselined data\n",
        "correlate_cole_moore_baselined(\n",
        "    exp_csv=exp_file,\n",
        "    shift_csv=shift_file,\n",
        "    derivative_csv=derivative_file,\n",
        "    invert_shifts=True  # Set to False if you don't want to invert trace alignment shifts\n",
        ")"
      ],
      "metadata": {
        "id": "_f4JTY4-Qr_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}